!! Copyright (C) 2002-2011 M. Marques, A. Castro, A. Rubio, G. Bertsch, M. Oliveira, J. Alberdi, P. Garcia RisueÃ±o
!!
!! This program is free software; you can redistribute it and/or modify
!! it under the terms of the GNU General Public License as published by
!! the Free Software Foundation; either version 2, or (at your option)
!! any later version.
!!
!! This program is distributed in the hope that it will be useful,
!! but WITHOUT ANY WARRANTY; without even the implied warranty of
!! MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
!! GNU General Public License for more details.
!!
!! You should have received a copy of the GNU General Public License
!! along with this program; if not, write to the Free Software
!! Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA
!! 02111-1307, USA.
!!
!! $Id$


! ---------------------------------------------------------
!> Allocates locally the real space grid, if PFFT library is not used.
!! Otherwise, it assigns the PFFT real space grid to the cube real space grid,
!! via pointer.
subroutine X(cube_function_alloc_RS)(cube, cf)
  type(cube_t),          intent(in)    :: cube
  type(cube_function_t), intent(inout) :: cf

  PUSH_SUB(X(cube_function_alloc_RS))

  ASSERT(.not.associated(cf%X(RS)))

  if (cube%fft_library /= FFTLIB_PFFT) then
    SAFE_ALLOCATE(cf%X(RS)(1:cube%rs_n(1), 1:cube%rs_n(2), 1:cube%rs_n(3)))
  else
    ASSERT(associated(cube%fft))
    cf%X(RS) => cube%fft%X(rs_data)(1:cube%rs_n(1), 1:cube%rs_n(2), 1:cube%rs_n(3))
  end if

  POP_SUB(X(cube_function_alloc_RS))
end subroutine X(cube_function_alloc_RS)


! ---------------------------------------------------------
!> Deallocates the real space grid
subroutine X(cube_function_free_RS)(cube, cf)
  type(cube_t),          intent(in)    :: cube
  type(cube_function_t), intent(inout) :: cf

  PUSH_SUB(X(cube_function_free_RS))

  if (cube%fft_library /= FFTLIB_PFFT) then
    SAFE_DEALLOCATE_P(cf%X(RS))
  else
    nullify(cf%X(RS))
  end if

  POP_SUB(X(cube_function_free_RS))
end subroutine X(cube_function_free_RS)

! ---------------------------------------------------------
#ifdef HAVE_MPI
subroutine X(cube_function_allgather)(cube, cf, cf_local)
  type(cube_t),   intent(in) :: cube
  R_TYPE,         intent(out) :: cf(:,:,:)
  R_TYPE,         intent(in)  :: cf_local(:,:,:)

  integer :: ix, iy, iz, index
  R_TYPE, allocatable :: cf_tmp(:)
  type(profile_t), save :: prof_allgather

  PUSH_SUB(X(cube_function_allgather))
  call profiling_in(prof_allgather, "CF_ALLGATHER")

  SAFE_ALLOCATE(cf_tmp(cube%n(1)*cube%n(2)*cube%n(3)))

  call mpi_debug_in(cube%mpi_grp%comm, C_MPI_ALLGATHERV)
  ! Warning: in the next line we have to pass the full cf_local array, not just the first element.
  ! This is because cf_local might be a pointer to a subarray when using PFFT, such that
  ! memory will not be contiguous (see cube_function_alloc_RS). In that case the 
  ! Fortran compiler should do a temporary copy.
  call MPI_Allgatherv ( cf_local, cube%np_local(cube%mpi_grp%rank+1), R_MPITYPE, &
       cf_tmp(1), cube%np_local, cube%xlocal - 1, R_MPITYPE, &
       cube%mpi_grp%comm, mpi_err)
  call mpi_debug_out(cube%mpi_grp%comm, C_MPI_ALLGATHERV)

  ! Copy values to cf in the correct order
  do index = 1, cube%n(1)*cube%n(2)*cube%n(3)
    ix = cube%local(index, 1)
    iy = cube%local(index, 2)
    iz = cube%local(index, 3)
    cf(ix, iy, iz) = cf_tmp(index)
  end do

  SAFE_DEALLOCATE_A(cf_tmp)

  call profiling_out(prof_allgather)

  POP_SUB(X(cube_function_allgather))
end subroutine X(cube_function_allgather)
#endif

! ---------------------------------------------------------
!> The next two subroutines convert a function between the normal
!! mesh and the cube.
!!
!! Note that the function in the mesh should be defined
!! globally, not just in a partition (when running in
!! parallel in real-space domains).
! ---------------------------------------------------------

subroutine X(mesh_to_cube)(mesh, mf, cube, cf, local)
  type(mesh_t),          intent(in)    :: mesh
  R_TYPE,  target,       intent(in)    :: mf(:) !< function defined on the mesh. Can be 
                                                !< mf(mesh%np) or mf(mesh%np_global), depending if it is a local or global function
  type(cube_t),          intent(in)    :: cube
  type(cube_function_t), intent(inout) :: cf
  logical, optional,     intent(in)    :: local  !< If .true. the mf array is a local array. Considered .false. if not present.

  integer :: ip, ix, iy, iz, center(3), ixyz(1:3)
  integer :: im, ii, nn
  logical :: local_
  R_TYPE, pointer :: gmf(:)

  PUSH_SUB(X(mesh_to_cube))
  call profiling_in(prof_m2c, "MESH_TO_CUBE")

  local_ = optional_default(local, .false.) .and. mesh%parallel_in_domains
  
  if(local_) then
    ASSERT(ubound(mf, dim = 1) == mesh%np .or. ubound(mf, dim = 1) == mesh%np_part)
    SAFE_ALLOCATE(gmf(1:mesh%np_global))
#ifdef HAVE_MPI
    call X(vec_allgather)(mesh%vp, gmf, mf)
#endif
  else
    ASSERT(ubound(mf, dim = 1) == mesh%np_global .or. ubound(mf, dim = 1) == mesh%np_part_global)
    gmf => mf
  end if

  ASSERT(associated(cf%X(RS)))

  center(1:3) = cube%n(1:3)/2 + 1

  cf%X(RS) = M_ZERO

  ASSERT(associated(mesh%cube_map%map))
  ASSERT(mesh%sb%dim <= 3)

  if(associated(mesh%idx%lxyz)) then

    do im = 1, mesh%cube_map%nmap
      ip = mesh%cube_map%map(MCM_POINT, im)
      nn = mesh%cube_map%map(MCM_COUNT, im)

      ix = mesh%idx%lxyz(ip, 1) + center(1)
      iy = mesh%idx%lxyz(ip, 2) + center(2)
      iz = mesh%idx%lxyz(ip, 3) + center(3)
      forall(ii = 0:nn - 1) cf%X(RS)(ix, iy, iz + ii) = gmf(ip + ii)
    end do

  else

    ixyz = 0
    do im = 1, mesh%cube_map%nmap
      ip = mesh%cube_map%map(MCM_POINT, im)
      nn = mesh%cube_map%map(MCM_COUNT, im)

      call index_to_coords(mesh%idx, mesh%sb%dim, ip, ixyz)
      ixyz = ixyz + center
      forall(ii = 0:nn - 1) cf%X(RS)(ixyz(1), ixyz(2), ixyz(3) + ii) = gmf(ip + ii)
    end do

  end if

  if(local_) then
    SAFE_DEALLOCATE_P(gmf)
  end if

  call profiling_count_transfers(mesh%np_global, mf(1))

  call profiling_out(prof_m2c)
  POP_SUB(X(mesh_to_cube))
end subroutine X(mesh_to_cube)

! ---------------------------------------------------------
subroutine X(cube_to_mesh) (cube, cf, mesh, mf, local)
  type(cube_t),          intent(in)  :: cube
  type(cube_function_t), intent(in)  :: cf
  type(mesh_t),          intent(in)  :: mesh
  R_TYPE,  target,       intent(out) :: mf(:) !< function defined on the mesh. Can be 
                                              !< mf(mesh%np) or mf(mesh%np_global), depending if it is a local or global function
  logical, optional,     intent(in)  :: local  !< If .true. the mf array is a local array. Considered .false. if not present.

  integer :: ip, ix, iy, iz, center(3), ixyz(1:3)
  integer :: im, ii, nn, last, first
  logical :: local_
  R_TYPE, pointer :: gmf(:)

  PUSH_SUB(X(cube_to_mesh))

  call profiling_in(prof_c2m, "CUBE_TO_MESH")

  local_ = optional_default(local, .false.) .and. mesh%parallel_in_domains
  
  if(local_) then
    ASSERT(ubound(mf, dim = 1) == mesh%np .or. ubound(mf, dim = 1) == mesh%np_part)
    SAFE_ALLOCATE(gmf(1:mesh%np_global))
  else
    ASSERT(ubound(mf, dim = 1) == mesh%np_global .or. ubound(mf, dim = 1) == mesh%np_part_global)
    gmf => mf
  end if

  ASSERT(associated(cf%X(RS)))

  center(1:3) = cube%n(1:3)/2 + 1

  ASSERT(associated(mesh%cube_map%map))

  if(associated(mesh%idx%lxyz)) then

    do im = 1, mesh%cube_map%nmap
      ip = mesh%cube_map%map(MCM_POINT, im)
      nn = mesh%cube_map%map(MCM_COUNT, im)
      ix = mesh%idx%lxyz(ip, 1) + center(1)
      iy = mesh%idx%lxyz(ip, 2) + center(2)
      iz = mesh%idx%lxyz(ip, 3) + center(3)
      forall(ii = 0:nn - 1) gmf(ip + ii) = cf%X(RS)(ix, iy, iz + ii)
    end do

  else

    ixyz = 0

    do im = 1, mesh%cube_map%nmap
      ip = mesh%cube_map%map(MCM_POINT, im)
      nn = mesh%cube_map%map(MCM_COUNT, im)

      call index_to_coords(mesh%idx, mesh%sb%dim, ip, ixyz)
      ixyz = ixyz + center

      forall(ii = 0:nn - 1) gmf(ip + ii) = cf%X(RS)(ixyz(1), ixyz(2), ixyz(3) + ii)
    end do

  end if

  if(local_) then
#ifdef HAVE_MPI
    first = mesh%vp%xlocal(mesh%vp%partno)
    last = mesh%vp%np_local(mesh%vp%partno)   
    do ii = 1, last
      mf(ii) = gmf(mesh%vp%local(ii+first-1))
    end do
#endif
    SAFE_DEALLOCATE_P(gmf)
  end if

  call profiling_count_transfers(mesh%np_global, mf(1))

  call profiling_out(prof_c2m)

  POP_SUB(X(cube_to_mesh))

end subroutine X(cube_to_mesh)

! ---------------------------------------------------------
!> The next two subroutines convert a function between the normal
!! mesh and the cube in parallel.
!!
!! ``Note that the function in the mesh should be defined
!! globally, not just in a partition (when running in
!! parallel in real-space domains).``
! ---------------------------------------------------------
subroutine X(mesh_to_cube_parallel)(mesh, mf, cube, cf, local, pfft_part)
  type(mesh_t),          intent(in)    :: mesh
  R_TYPE,  target,       intent(in)    :: mf(:)  !< mf(mesh%np_global)
  type(cube_t),          intent(in)    :: cube
  type(cube_function_t), intent(inout) :: cf
  logical, optional,     intent(in)    :: local  !< If .true. the mf array is a local array. Considered .false. if not present.
  logical, optional,     intent(in)    :: pfft_part !< If .true. the used partition is the pfft equal partition

  integer :: ip, ix, iy, iz, center(3)
  integer :: im, ii, nn
  integer :: min_x, min_y, min_z, max_x, max_y, max_z
  logical :: local_, pfft_part_
  R_TYPE, pointer :: gmf(:)

  PUSH_SUB(X(mesh_to_cube_parallel))
  call profiling_in(prof_m2c, "MESH_TO_CUBE_PARALLEL")

  local_ = optional_default(local, .false.) .and. mesh%parallel_in_domains
  pfft_part_ = optional_default(pfft_part, .false.) 
  if (pfft_part_) then
    ASSERT(ubound(mf, dim=1) == mesh%np)
  else
    if(local_) then
      ASSERT(ubound(mf, dim = 1) == mesh%np .or. ubound(mf, dim = 1) == mesh%np_part)
      SAFE_ALLOCATE(gmf(1:mesh%np_global))
#ifdef HAVE_MPI
      call X(vec_allgather)(mesh%vp, gmf, mf)
#endif
    else
      ASSERT(ubound(mf, dim = 1) == mesh%np_global .or. ubound(mf, dim = 1) == mesh%np_part_global)
      gmf => mf
    end if
  end if

  center(1:3) = cube%n(1:3)/2 + 1

  ! Save the limit values
  min_x = cube%rs_istart(1)
  min_y = cube%rs_istart(2)
  min_z = cube%rs_istart(3)
  max_x = cube%rs_istart(1) + cube%rs_n(1)
  max_y = cube%rs_istart(2) + cube%rs_n(2)
  max_z = cube%rs_istart(3) + cube%rs_n(3)
  
  ! Initialize to zero the input matrix
  forall(iz = 1:cube%rs_n(3), iy = 1:cube%rs_n(2), ix = 1:cube%rs_n(1)) cf%X(RS)(ix, iy, iz) = M_ZERO

  ! Do the actual transform, only for the output values
  do im = 1, mesh%cube_map%nmap
    ip = mesh%cube_map%map(MCM_POINT, im)
    nn = mesh%cube_map%map(MCM_COUNT, im)
    
    ix = mesh%idx%lxyz(ip, 1) + center(1)
    if (ix >= min_x .and. ix < max_x) then
      iy = mesh%idx%lxyz(ip, 2) + center(2)
      if (iy >= min_y .and. iy < max_y) then
        iz = mesh%idx%lxyz(ip, 3) + center(3)
        do ii = 0, nn - 1
          if (iz+ii >= min_z .and. iz+ii < max_z) then

            if (pfft_part_) then
#ifdef HAVE_MPI
              cf%X(RS)(ix-min_x+1, iy-min_y+1, iz+ii-min_z+1) = mf(vec_global2local(mesh%vp,ip+ii, mesh%vp%partno))
#endif
            else
              cf%X(RS)(ix-min_x+1, iy-min_y+1, iz+ii-min_z+1) = gmf(ip + ii)
            end if
          end if
        end do
      end if
    end if

  end do
  
  if(local_) then
    SAFE_DEALLOCATE_P(gmf)
  end if

  call profiling_count_transfers(mesh%np_global, mf(1))

  call profiling_out(prof_m2c)
  POP_SUB(X(mesh_to_cube_parallel))
end subroutine X(mesh_to_cube_parallel)

! ---------------------------------------------------------
subroutine X(cube_to_mesh_parallel) (cube, cf, mesh, mf, local, pfft_part)
  type(cube_t),          intent(in)  :: cube
  type(cube_function_t), intent(in)  :: cf
  type(mesh_t),          intent(in)  :: mesh
  R_TYPE, target,        intent(out) :: mf(:)  !< mf(mesh%np_global)
  logical, optional,     intent(in)  :: local  !< If .true. the mf array is a local array. Considered .false. if not present.
  logical, optional,     intent(in)  :: pfft_part !< If .true. the used partition is the pfft equal partition

  integer :: ip, im, ii, nn, center(3), ixyz(3), lxyz(3)
  integer :: last, first
  logical :: local_, pfft_part_
  R_TYPE, pointer :: gmf(:)
  R_TYPE, allocatable :: gcf(:,:,:)

  PUSH_SUB(X(cube_to_mesh_parallel))

  call profiling_in(prof_c2m, "CUBE_TO_MESH_PARALLEL")

  local_ = optional_default(local, .false.) .and. mesh%parallel_in_domains
  pfft_part_ = optional_default(pfft_part, .false.) 
  if (pfft_part_) then
    ASSERT(ubound(mf, dim=1) == mesh%np)
  else
    if(local_) then
      ASSERT(ubound(mf, dim = 1) == mesh%np .or. ubound(mf, dim = 1) == mesh%np_part)
      SAFE_ALLOCATE(gmf(1:mesh%np_global))
    else
      ASSERT(ubound(mf, dim = 1) == mesh%np_global .or. ubound(mf, dim = 1) == mesh%np_part_global)
      gmf => mf
    end if
  end if
  
  center(1:3) = cube%n(1:3)/2 + 1

  if (pfft_part_) then

    do im = 1, mesh%cube_map%nmap
      ip = mesh%cube_map%map(MCM_POINT, im)
      nn = mesh%cube_map%map(MCM_COUNT, im)

      do ii = 0, nn - 1
        ixyz(1:3) = mesh%idx%lxyz(ip + ii, 1:3) + center(1:3)

        if (cube_global2local(cube, ixyz, lxyz)) then
#ifdef HAVE_MPI
          mf(vec_global2local(mesh%vp,ip+ii, mesh%vp%partno)) = cf%X(RS)(lxyz(1), lxyz(2), lxyz(3))
#endif
        end if
      end do
    end do

  else

    !collect the data in all processes
    SAFE_ALLOCATE(gcf(cube%n(1), cube%n(2), cube%n(3)))
#ifdef HAVE_MPI
    call X(cube_function_allgather)(cube, gcf, cf%X(RS))
#endif

    ! cube to mesh
    do im = 1, mesh%cube_map%nmap
      ip = mesh%cube_map%map(MCM_POINT, im)
      nn = mesh%cube_map%map(MCM_COUNT, im)

      ixyz(1:3) = mesh%idx%lxyz(ip, 1:3) + center(1:3)
      do ii = 0, nn - 1
        if (mpi_world%size == 1) then
          gmf(ip + ii) = gcf(ixyz(1), ixyz(2), ixyz(3) + ii)
        else
          if (mesh%vp%part(ip+ii) == mesh%vp%partno) then
            gmf(ip + ii) = gcf(ixyz(1), ixyz(2), ixyz(3) + ii)
          end if
        end if
      end do
    end do

    SAFE_DEALLOCATE_A(gcf)

    !Rearrange the output matrix
    if(local_) then
#ifdef HAVE_MPI
      first = mesh%vp%xlocal(mesh%vp%partno)
      last = mesh%vp%np_local(mesh%vp%partno)
      do ii = 1, last
        mf(ii) = gmf(mesh%vp%local(ii+first-1))
      end do
#endif
      SAFE_DEALLOCATE_P(gmf)
    end if
  end if

  call profiling_count_transfers(mesh%np_global, mf(1))
  call profiling_out(prof_c2m)

  POP_SUB(X(cube_to_mesh_parallel))

end subroutine X(cube_to_mesh_parallel)

!! Local Variables:
!! mode: f90
!! coding: utf-8
!! End:
