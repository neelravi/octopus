!! Copyright (C) 2005-2006 Florian Lorenzen, Heiko Appel
!!
!! This program is free software; you can redistribute it and/or modify
!! it under the terms of the GNU General Public License as published by
!! the Free Software Foundation; either version 2, or (at your option)
!! any later version.
!!
!! This program is distributed in the hope that it will be useful,
!! but WITHOUT ANY WARRANTY; without even the implied warranty of
!! MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
!! GNU General Public License for more details.
!!
!! You should have received a copy of the GNU General Public License
!! along with this program; if not, write to the Free Software
!! Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA
!! 02111-1307, USA.
!!
!! $Id$

#include "global.h"

module par_vec_m

  ! Some general things and nomenclature:
  !
  ! - Points that are stored only on one node are
  !   called local points.
  ! - Local points, that are stored redundantly on
  !   another node because of the partitioning are
  !   called ghost points.
  ! - Points from the enlargement are only stored
  !   once on the corresponding node and are called
  !   boundary points.
  ! - np ist the total number of inner points.
  !
  ! When working with non-periodic boundary conditions
  ! a globally defined vector v has two parts:
  ! - v(1:np) are the inner points
  ! - v(np+1:np_part) are the boundary points
  ! In the typical case of zero boundary conditions
  ! v(np+1:np_part) is 0.
  ! The two parts are split according to the partitions.
  ! The result of this split are local vectors vl on each node
  ! which consist of three parts:
  ! - vl(1:np_local)                                     local points.
  ! - vl(np_local+1:np_local+np_ghost)                   ghost points.
  ! - vl(np_local+np_ghost+1:np_local+np_ghost+np_bndry) boundary points.
  !
  !
  ! Usage example for par_vec routines.
  !
  ! ! Initialize parallelization with mesh m and operator op
  ! ! initialized and given.
  ! ! m          = sys%gr%m
  ! ! stencil    = op%stencil
  ! ! np_stencil = op%n
  !
  ! FLOAT              :: s
  ! FLOAT              :: u(np_global), v(np_global)
  ! FLOAT, allocatable :: ul(:), vl(:), wl(:)
  ! type(mesh_t)    :: m
  !
  ! ! Fill u, v with sensible values.
  ! ! ...
  !
  ! /*
  ! ! Allocate space for local vectors.
  ! ALLOCATE(ul(np_part), np_part)
  ! ALLOCATE(vl(np_part), np_part)
  ! ALLOCATE(wl(np_part), np_part)
  ! */
  !
  ! ! Distribute vectors.
  ! call X(vec_scatter)(vp, u, ul)
  ! call X(vec_scatter)(vp, v, vl)
  !
  ! ! Calculate scalar product s=<u|v>.
  ! wl = ul*vl
  ! ! vec_integrate ignores ghost points (i. e. v(np_local+1:)).
  ! s = X(vec_integrate)(vp, wl)
  !
  ! ! Compute some operator op: vl = op ul
  ! call X(vec_ghost_update)(vp, ul)
  ! call X(nl_operator_operate)(op, ul, vl)
  ! ! Gather result of op in one vector v.
  ! call X(vec_gather)(vp, v, vl)
  !
  ! ! Clean up.
  ! deallocate(ul, vl, wl)

  use c_pointer_m
  use global_m
  use io_m
  use mesh_lib_m
  use messages_m
  use mpi_debug_m
  use mpi_m
  use profiling_m

  implicit none

  private
  public :: pv_t

  type pv_t
    ! The content of these members is node dependent.
    integer          :: rank                 ! Our rank in the communicator.
    integer          :: partno               ! Partition number of the
                                             ! current node
    ! The following members are set independent of the nodes.
    integer          :: p                    ! Number of partitions.
    integer          :: root                 ! The master node.
    integer          :: comm                 ! MPI communicator to use.
    integer          :: np                   ! Number of points in mesh.
    integer          :: np_enl               ! Number of points in enlargement.
    integer, pointer :: part(:)              ! Point -> partition.
    integer, pointer :: np_local(:)          ! How many points has partition r?
    integer, pointer :: xlocal(:)            ! Points of partition r start at
                                             ! xlocal(r) in local.
    integer, pointer :: local(:)             ! Partition r has points
                                             ! local(xlocal(r):
                                             ! xlocal(r)+np_local(r)-1).
    integer, pointer :: np_bndry(:)          ! Number of boundary points.
    integer, pointer :: xbndry(:)            ! Index of bndry(:).
    integer, pointer :: bndry(:)             ! Global numbers of boundary
                                             ! points.
    integer, pointer :: global(:, :)         ! global(i, r) is local number
                                             ! of point i in partition r
                                             ! (if this is 0, i is neither
                                             ! a ghost point nor local to r).
    integer          :: total                ! Total number of ghost points.
    integer, pointer :: np_ghost(:)          ! How many ghost points has
                                             ! partition r?
    integer, pointer :: np_ghost_neigh(:, :) ! Number of ghost points per
                                             ! neighbour per partition.
    integer, pointer :: xghost(:)            ! Like xlocal.
    integer, pointer :: xghost_neigh(:, :)   ! Like xghost for neighbours.
    integer, pointer :: ghost(:)             ! Global indices of all local
                                             ! ghost points.
  end type pv_t

#if defined(HAVE_MPI)
  public ::              &
    vec_init,            &
    vec_end,             &
    dvec_scatter,        &
    zvec_scatter,        &
    ivec_scatter,        &
    dvec_scatter_bndry,  &
    zvec_scatter_bndry,  &
    ivec_scatter_bndry,  &
    dvec_scatter_all,    &
    zvec_scatter_all,    &
    ivec_scatter_all,    &
    dvec_gather,         &
    zvec_gather,         &
    ivec_gather,         &
    dvec_allgather,      &
    zvec_allgather,      &
    ivec_allgather,      &
    dvec_ghost_update,   &
    zvec_ghost_update,   &
    ivec_ghost_update,   &
#if defined(HAVE_LIBNBC)
    dvec_ighost_update,  &
    zvec_ighost_update,  &
    ivec_ighost_update,  &
#endif
    dvec_integrate,      &
    zvec_integrate,      &
    ivec_integrate

contains

  ! Initializes a pv_type object (parallel vector).
  ! It computes the local to global and global to local index tables
  ! and the ghost point exchange.
  ! The format for the stencil is: stencil(3, i) for i=1, ..., np_stencil
  ! (as for type(nl_operator_t)).
  ! For example a stencil like (in x-y-plane)
  !          .
  !        .....
  !          .
  ! is coded as
  !   stencil(:, 1) = (/ 0,  1,  0/)
  !   stencil(:, 2) = (/-2,  0,  0/)
  !   stencil(:, 3) = (/-1,  0,  0/)
  !   stencil(:, 3) = (/ 0,  0,  0/)
  !   stencil(:, 5) = (/ 1,  0,  0/)
  !   stencil(:, 6) = (/ 2,  0,  0/)
  !   stencil(:, 7) = (/ 0, -1,  0/)
  ! The points are relative to the "application point" of the stencil.
  ! (This is the same format as used in type(nl_operator_t), so
  ! just passing op%stencil is possible.)
  ! Note: we can not pass in the i(:, :) array from the stencil
  ! because it is not yet computed (it is local to a node and
  ! must be initialized some time after vec_init is run).
  ! Warning: The naming scheme for the np_ variables if different
  ! from how it is in the rest of the code (for historical reasons
  ! and also because the vec_init has more a global than a local point
  ! of view on the mesh): See the comments in the parameter list.
  subroutine vec_init(comm, root, part, np, np_part, nr, &
    Lxyz_inv, Lxyz, stencil, np_stencil, dim, vp)
    integer,       intent(in)  :: comm         ! Communicator to use.
    integer,       intent(in)  :: root         ! The master node.
    ! The next seven entries come from the mesh.
    integer,       intent(in)  :: part(:)      ! Point -> partition.
    integer,       intent(in)  :: np           ! m%np_global
    integer,       intent(in)  :: np_part      ! m%np_part_global
    integer,       intent(in)  :: nr(2, 3)     ! m%nr
    integer,       intent(in)  :: Lxyz_inv(nr(1,1):nr(2,1), &
                                           nr(1,2):nr(2,2), &
                                           nr(1,3):nr(2,3))
                                               ! m%Lxyz_inv
    integer,       intent(in)  :: Lxyz(:, :)   ! m%Lxyz
    integer,       intent(in)  :: stencil(:,:) ! The stencil for which to
    ! calculate ghost points.
    integer,       intent(in)  :: np_stencil   ! Num. of points in stencil.
    integer,       intent(in)  :: dim          ! Number of dimensions.
    type(pv_t), intent(out) :: vp           ! Description of partition.

    ! Careful: MPI counts node ranks from 0 to numproc-1.
    ! Partition numbers from METIS range from 1 to numproc.
    ! For this reason, all ranks are incremented by one.
    integer              :: p                ! Number of partitions.
    integer              :: np_enl           ! Number of points in enlargement.
    integer              :: i, j, k, r       ! Counters.
    integer, allocatable :: ir(:), irr(:, :) ! Counters.
    integer              :: rank             ! Rank of current node.
    integer              :: p1(MAX_DIM)      ! Points.
    integer, allocatable :: ghost_flag(:, :) ! To remember ghost pnts.
    integer              :: iunit            ! For debug output to files.
    character(len=3)     :: filenum

    call push_sub('par_vec.vec_init')

    ! Shortcuts.
    call MPI_Comm_Size(comm, p, mpi_err)
    np_enl = np_part-np

    ! Store partition number and rank for later reference.
    ! Having both variables is a bit redundant but makes the code readable.
    call MPI_Comm_Rank(comm, rank, mpi_err)
    vp%rank   = rank
    vp%partno = rank + 1

    ALLOCATE(ghost_flag(np+np_enl, p), (np+np_enl)*p)
    ALLOCATE(ir(p),                    p)
    ALLOCATE(irr(p, p),                p*p)
    ALLOCATE(vp%part(np+np_enl),       np+np_enl)
    ALLOCATE(vp%np_local(p),           p)
    ALLOCATE(vp%xlocal(p),             p)
    ALLOCATE(vp%local(np),             np)
    ALLOCATE(vp%np_bndry(p),           p)
    ALLOCATE(vp%xbndry(p),             p)
    ALLOCATE(vp%bndry(np_enl),         np_enl)
    ALLOCATE(vp%global(np+np_enl, p),  (np+np_enl)*p)
    ALLOCATE(vp%np_ghost(p),           p)
    ALLOCATE(vp%np_ghost_neigh(p, p),  p*p)
    ALLOCATE(vp%xghost(p),             p)
    ALLOCATE(vp%xghost_neigh(p, p),    p*p)

    ! Count number of points for each node.
    ! Local points.
    vp%np_local = 0
    do i = 1, np
      vp%np_local(part(i)) = vp%np_local(part(i))+1
    end do
    ! Boundary points.
    vp%np_bndry = 0
    do i = 1, np_enl
      vp%np_bndry(part(i+np)) = vp%np_bndry(part(i+np))+1
    end do

    ! Set up local to global index table for local points
    ! (xlocal, local) and for boundary points (xbndry, bndry).
    vp%xlocal(1) = 1
    vp%xbndry(1) = 1
    do r = 2, p
      vp%xlocal(r) = vp%xlocal(r-1)+vp%np_local(r-1)
      vp%xbndry(r) = vp%xbndry(r-1)+vp%np_bndry(r-1)
    end do
    ir = 0
    do i = 1, np
      vp%local(vp%xlocal(part(i))+ir(part(i))) = i
      ir(part(i))                              = ir(part(i))+1
    end do
    ir = 0
    do i = np+1, np+np_enl
      vp%bndry(vp%xbndry(part(i))+ir(part(i))) = i
      ir(part(i))                              = ir(part(i))+1
    end do

    ! Format of ghost:
    !
    ! np_ghost_neigh, np_ghost, xghost_neigh, xghost are components of vp, the vp% is
    ! ommited due to space constraints.
    !
    ! The following figure shows, how ghost points of node r are put into ghost:
    !
    !  |<--------------------------------np_ghost(r)---------------------------------->|
    !  |                                                                               |
    !  |<-np_ghost_neigh(r,1)->|     |<-np_ghost_neigh(r,p-1)->|<-np_ghost_neigh(r,p)->|
    !  |                       |     |                         |                       |
    ! -----------------------------------------------------------------------------------
    !  |                       | ... |                         |                       |
    ! -----------------------------------------------------------------------------------
    !  ^                             ^                         ^
    !  |                             |                         |
    !  xghost_neigh(r,1)             xghost_neigh(r,p-1)       xghost_neigh(r,p)
    !  |
    !  xghost(r)

    ! Mark and count ghost points and neighbours
    ! (set vp%np_ghost_neigh, vp%np_ghost, ghost_flag).
    vp%total          = 0
    ghost_flag        = 0
    vp%np_ghost_neigh = 0
    vp%np_ghost       = 0
    ! Check all nodes.
    do r = 1, p
      ! Check all points of this node.
      do i = vp%xlocal(r), vp%xlocal(r)+vp%np_local(r)-1
        ! Get coordinates of current point.
        p1 = Lxyz(vp%local(i), :)
        ! For all points in stencil.
        do j = 1, np_stencil
          ! Get point number of possible ghost point.
          ! mesh_index takes care of periodic dimensions and
          ! out points that would be out of the box etc.
          k = mesh_index(dim, nr, Lxyz_inv, p1(:) + stencil(:, j))
          ASSERT(k.ne.0)
          ! If this index k does not belong to partition of node r,
          ! then k is a ghost point for r with part(k) now being
          ! a neighbour of r.
          if(part(k).ne.r) then
            ! Only mark and count this ghost point, if it is not
            ! done yet. Otherwise, points would possibly be registered
            ! more than once.
            if(ghost_flag(k, r).eq.0) then
              ! Mark point i as ghost point for r from part(k).
              ghost_flag(k, r)                = part(k)
              ! Increase number of ghost points of r from part(k).
              vp%np_ghost_neigh(r, part(k)) = vp%np_ghost_neigh(r, part(k))+1
              ! Increase total number of ghostpoints of r.
              vp%np_ghost(r)                  = vp%np_ghost(r)+1
              ! One more ghost point.
              vp%total                        = vp%total+1
            end if
          end if
        end do
      end do
    end do

    ! Set index tables xghost and xghost_neigh.
    vp%xghost(1) = 1
    do r = 2, p
      vp%xghost(r) = vp%xghost(r-1)+vp%np_ghost(r-1)
    end do
    do r = 1, p
      vp%xghost_neigh(r, 1) = vp%xghost(r)
      do j = 2, p
        vp%xghost_neigh(r, j) = vp%xghost_neigh(r, j-1)    &
          +vp%np_ghost_neigh(r, j-1)
      end do
    end do

    ! Get space for ghost point vector.
    ALLOCATE(vp%ghost(vp%total), vp%total)

    ! Fill ghost as described above.
    irr = 0
    do i = 1, np+np_enl
      do r = 1, p
        j = ghost_flag(i, r)
        ! If point i is a ghost point for r from j, save this
        ! information.
        if(j.ne.0) then
          vp%ghost(vp%xghost_neigh(r, j)+irr(r, j)) = i
          irr(r, j)                                 = irr(r, j)+1
        end if
      end do
    end do

    message(1) = 'Info: Number of ghost points per node:'
    write(message(2), '(a,f10.2,a,i7,a,i7)') &
         'Info: Average =', sum(vp%np_ghost)/dble(p), '  Minimum =', minval(vp%np_ghost), '  Maximum =', maxval(vp%np_ghost)
    call write_info(2)

    if(in_debug_mode) then
      ! Write numbers and coordinates of each nodes ghost points
      ! to a single file (like in mesh_partition_init) called
      ! debug/mesh_partition/ghost_points.###.
      if(mpi_grp_is_root(mpi_world)) then
        call io_mkdir('debug/mesh_partition')
        do r = 1, p
          write(filenum, '(i3.3)') r
          iunit = io_open('debug/mesh_partition/ghost_points.'//filenum, &
            action='write')
          do i = 1, vp%np_ghost(r)
            j = vp%ghost(vp%xghost(r)+i-1)
            write(iunit, '(4i8)') j, Lxyz(j, :)
          end do
          call io_close(iunit)
        end do
      end if
    end if

    ! Create reverse (global to local) lookup.
    ! Given a global point number i and a vector v_local of
    ! length vp%np_local(r)+vp%np_ghost(r)+vp%np_bndry(r) global(i, r) gives
    ! the index of point i in v_local as long as this point is
    ! local to r or a ghost point for r (if vp%np_bndry(r) >
    ! global(i, r) > vp%np_local(r) it is a ghost point).
    ! If global(i, r) is 0 then i is neither local
    ! to r nor a ghost point of r. This indicates a serious error.
    ! Note: The global array may consume too much memory for many
    ! nodes and points, e. g. about 64MB for 16 nodes and half a
    ! million points on a 64 bit architecture.
    ! The solution is then to introduce a function global which
    ! does the mapping. This function does a binary search in the
    ! sorted array of global point numbers the node has,
    ! which will hopefully be fast enough (O(log n)). This avoids
    ! storing all those 0.
    ! global is mainly used in initialization, so speed is not too
    ! important.

    !$omp parallel

    !$omp do
    do r = 1, p
      vp%global(1:np+np_enl, r) = 0
    end do
    !$omp end do nowait
    
    !$omp do private(i)
    do r = 1, p
      ! Local points.
      do i = 1, vp%np_local(r)
        vp%global(vp%local(vp%xlocal(r) + i - 1), r) = i
      end do
      ! Ghost points.
      do i = 1, vp%np_ghost(r)
        vp%global(vp%ghost(vp%xghost(r) + i - 1), r) = vp%np_local(r) + i
      end do
      ! Boundary points.
      do i = 1, vp%np_bndry(r)
        vp%global(vp%bndry(vp%xbndry(r) + i - 1), r) =  vp%np_local(r) + vp%np_ghost(r)+i
      end do
    end do
    !$omp end do

    !$omp end parallel
    
    ! Complete entries in vp.
    vp%comm   = comm
    vp%root   = root
    vp%np     = np
    vp%np_enl = np_enl
    vp%p      = p
    vp%part   = part

    call pop_sub()
  end subroutine vec_init


  ! Deallocate memory used by vp.
  subroutine vec_end(vp)
    type(pv_t), intent(inout) :: vp

    call push_sub('par_vec.vec_end')

    if(associated(vp%part)) then
      deallocate(vp%part)
      nullify(vp%part)
    end if
    if(associated(vp%np_local)) then
      deallocate(vp%np_local)
      nullify(vp%np_local)
    end if
    if(associated(vp%xlocal)) then
      deallocate(vp%xlocal)
      nullify(vp%xlocal)
    end if
    if(associated(vp%local)) then
      deallocate(vp%local)
      nullify(vp%local)
    end if
    if(associated(vp%np_bndry)) then
      deallocate(vp%np_bndry)
      nullify(vp%np_bndry)
    end if
    if(associated(vp%xbndry)) then
      deallocate(vp%xbndry)
      nullify(vp%xbndry)
    end if
    if(associated(vp%bndry)) then
      deallocate(vp%bndry)
      nullify(vp%bndry)
    end if
    if(associated(vp%global)) then
      deallocate(vp%global)
      nullify(vp%global)
    end if
    if(associated(vp%np_ghost)) then
      deallocate(vp%np_ghost)
      nullify(vp%np_ghost)
    end if
    if(associated(vp%np_ghost_neigh)) then
      deallocate(vp%np_ghost_neigh)
      nullify(vp%np_ghost_neigh)
    end if
    if(associated(vp%xghost)) then
      deallocate(vp%xghost)
      nullify(vp%xghost)
    end if
    if(associated(vp%xghost_neigh)) then
      deallocate(vp%xghost_neigh)
      nullify(vp%xghost_neigh)
    end if
    if(associated(vp%ghost)) then
      deallocate(vp%ghost)
      nullify(vp%ghost)
    end if

    call pop_sub()

  end subroutine vec_end


#include "undef.F90"
#include "complex.F90"
#include "par_vec_inc.F90"

#include "undef.F90"
#include "real.F90"
#include "par_vec_inc.F90"

#include "undef.F90"
#include "integer.F90"
#include "par_vec_inc.F90"

#endif
end module par_vec_m

!! Local Variables:
!! mode: f90
!! coding: utf-8
!! End:
